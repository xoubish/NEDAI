{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405ffb67-430e-4d98-8670-a0ec5453358d",
   "metadata": {},
   "source": [
    "# Preparing Data for Fine-tuning a NER Model\n",
    "started Oct 17th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f56069-da58-4756-81bf-59f021663f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679815f-89fb-49e6-8713-e49e4d929a15",
   "metadata": {},
   "source": [
    "### 1. **Data Collection**\n",
    "- Gather text data representative of your content.\n",
    "- If your dataset is insufficient, consider augmenting it with more representative examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03ed9ac1-98ab-462e-80b9-26d71ccfbde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "258 133\n"
     ]
    }
   ],
   "source": [
    "# Read in html sections and tables\n",
    "with open('2022ApJ...924...14P.html') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    \n",
    "#to inspect html and identify the class label\n",
    "#print(soup.prettify()) \n",
    "\n",
    "#get texts from the html:\n",
    "sections = soup.find_all('div', class_=\"article-text\")\n",
    "print(len(sections))\n",
    "\n",
    "\n",
    "# Extracting all paragraphs in the section\n",
    "paragraphs = soup.find_all('p')\n",
    "ps=0\n",
    "for i, para in enumerate(paragraphs):\n",
    "    p = para.get_text()\n",
    "    if (len(p)>100) and (p[0].isalpha()):\n",
    "        #print(f\"Paragraph {i+1}:\", p)\n",
    "        #print('--------------')\n",
    "        ps+=1\n",
    "print(i,ps)\n",
    "\n",
    "# Read in label file \n",
    "\n",
    "#find where in section or table they are mentioned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d2c15-b4c9-4fc3-a1af-02f9e831e5ba",
   "metadata": {},
   "source": [
    "### 2. **Annotation**\n",
    "- Mark and label entities within your text.\n",
    "- Entities to start with: `Object Name`, `RA`, `DEC`, `Redshift`, `Type`. We may add more later.\n",
    "#### 2.1 **Figure out annotation formats**\n",
    "Data can be represented in various formats:\n",
    "- **BIO (or IOB) Format**\n",
    "- **CoNLL Format**: Columns-based, used in datasets like CoNLL-2003. **will go with this for now**\n",
    "- **Spacy Format**: JSON format (for Spacy users) with entities represented by start/end character positions.\n",
    "\n",
    "Manual annotation can be time-consuming. If NED had not already done some part of this we could have considered: [Doccano](https://doccano.herokuapp.com/), [Prodigy](https://prodi.gy/) (by Spacy creators, paid), [Labelbox](https://www.labelbox.com/), or [Brat](http://brat.nlplab.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b2bab6-e700-4ac7-9362-0b6f14f1534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John B-PERSON\n",
      "S. I-PERSON\n",
      "Maro I-PERSON\n",
      "lives O\n",
      "in O\n",
      "New B-LOCATION\n",
      "York I-LOCATION\n",
      "and O\n",
      "is O\n",
      "tired. O\n",
      "He O\n",
      "is O\n",
      "27.2 B-AGE\n",
      "years O\n",
      "old O\n"
     ]
    }
   ],
   "source": [
    "text = \"John S. Maro lives in New York and is tired. He is 27.2 years old\"\n",
    "entities = [(\"John S. Maro\", \"PERSON\"), (\"New York\", \"LOCATION\"), (\"27.2\",\"AGE\")]\n",
    "\n",
    "# Step 1: Tokenize\n",
    "tokens = text.split()  # Simplistic whitespace tokenization\n",
    "labels = ['O'] * len(tokens)  # Step 2: Initialize with 'O' tags\n",
    "\n",
    "# Step 3: Match entities and assign tags\n",
    "for entity, entity_type in entities:\n",
    "    entity_tokens = entity.split()\n",
    "    for i in range(len(tokens) - len(entity_tokens) + 1):\n",
    "        if tokens[i:i+len(entity_tokens)] == entity_tokens:\n",
    "            labels[i] = \"B-\" + entity_type\n",
    "            for j in range(1, len(entity_tokens)):\n",
    "                labels[i+j] = \"I-\" + entity_type\n",
    "\n",
    "# Step 4: Compile to CoNLL format\n",
    "conll_data = \"\\n\".join([f\"{token} {label}\" for token, label in zip(tokens, labels)])\n",
    "\n",
    "print(conll_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbef0a9-9890-4789-bde3-a02649b8748e",
   "metadata": {},
   "source": [
    "### 3. **Train/Test Split**\n",
    "- Consider an 80% training, 10% validation, and 10% test split.\n",
    "- Respect document boundaries to avoid overlap between sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ff4a8-69a3-49e1-a304-0bb4b0b6a729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e117e8-49f2-47dc-91d8-b4b8466f1cf0",
   "metadata": {},
   "source": [
    "### 4. **Preprocessing**\n",
    "- Tokenize consistently with the pre-trained model's tokenization.\n",
    "- Other steps might include converting to lowercase, handling punctuation, etc.\n",
    "\n",
    "### 5. **Model-Specific Formatting**\n",
    "- Convert data to be compatible with your chosen framework.\n",
    "- For HuggingFace Transformers, use their `TokenClassification` model format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33293be4-3580-4197-b5d6-3991fe7b584c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "add9b995-d2d0-4c0a-ba8d-d507c7244417",
   "metadata": {},
   "source": [
    "### 6. **Augmentation (Optional)**\n",
    "For smaller datasets, consider:\n",
    "- Back translation\n",
    "- Synonym replacement\n",
    "- Sentence shuffling\n",
    "\n",
    "### 7. **Data Quality Checks**\n",
    "- Ensure annotation consistency.\n",
    "- Address issues like overlapping annotations or mislabeled entities.\n",
    "\n",
    "After data preparation, proceed with fine-tuning your NER model, evaluating on the validation set and tuning hyperparameters as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ebed2-ee91-4d28-9e0e-09279fce6a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
