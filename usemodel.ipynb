{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70007b0c-45a8-4276-a8fc-1ed23bec83e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14742/9609891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from transformers import (\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-ap_name1\",\n",
    "    2: \"I-ap_name1\",\n",
    "    3: \"B-vz1\",\n",
    "    4: \"I-vz1\",\n",
    "    5: \"B-coordx1\",\n",
    "    6: \"I-coordx1\",\n",
    "    7: \"B-coordy1\",\n",
    "    8: \"I-coordy1\",\n",
    "    9: \"B-type1\",\n",
    "    10: \"I-type1\",\n",
    "}\n",
    "label2id = {\"O\": 0,\n",
    "          \"B-ap_name1\": 1,\n",
    "          \"I-ap_name1\": 2,\n",
    "          \"B-vz1\": 3,\n",
    "          \"I-vz1\": 4,\n",
    "          \"B-coordx1\": 5,\n",
    "          \"I-coordx1\": 6,\n",
    "          \"B-coordy1\": 7,\n",
    "          \"I-coordy1\": 8,\n",
    "          \"B-type1\": 9,\n",
    "          \"I-type1\": 10,\n",
    "         }\n",
    "\n",
    "def get_html_text(f,plength=100):\n",
    "    with open(f) as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "    #to inspect html and identify the class label\n",
    "    #print(soup.prettify()) \n",
    "    sections = soup.find_all('div', class_=\"article-text\")\n",
    "\n",
    "    # Extracting all paragraphs in the section\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ''\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        p = para.get_text()\n",
    "        if (len(p)>plength) and (p[0].isalpha()):\n",
    "            text+=p\n",
    "            #print(f\"Paragraph {i+1}:\", p)\n",
    "            #print('--------------')\n",
    "    #text = re.sub(r'[^a-zA-Z0-9 .,]', '', text)#.lower()\n",
    "    return text\n",
    "\n",
    "def format_pred_for_print(pred, paragraph):\n",
    "    '''\n",
    "    returns a pretty string with the predictions in paragraph highlighted.\n",
    "    pred: prediction output from a pipeline\n",
    "    paragraph: the original text the predictions were made on\n",
    "    '''\n",
    "    \n",
    "    RED_START = '\\x1b[31m'\n",
    "    RED_END = '\\x1b[0m'\n",
    "    \n",
    "    formatted_string=''\n",
    "    end=0\n",
    "    \n",
    "    for entry in pred:\n",
    "        start = entry['start']\n",
    "        # add what's in between\n",
    "        formatted_string += paragraph[end:start]\n",
    "        # add the entry\n",
    "        end = entry['end']\n",
    "        label = entry['entity']\n",
    "        score = ' {:.2f}'.format(entry['score'])\n",
    "        formatted_string+= RED_START+'['+paragraph[start:end]+' ('+label+score+')]'+RED_END\n",
    "        \n",
    "    formatted_string+= paragraph[end:]\n",
    "    return(formatted_string)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "peft_model_id = 'NER-BERT-lora-token-classification/checkpoint-182580/'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "tokenizerpeft = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "inference_model = AutoModelForTokenClassification.from_pretrained(config.base_model_name_or_path, num_labels=11, id2label=id2label, label2id=label2id,ignore_mismatched_sizes=True)\n",
    "modelpeft = PeftModel.from_pretrained(inference_model, peft_model_id)\n",
    "nlpeft = pipeline(\"ner\", model=modelpeft, tokenizer=tokenizerpeft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b1cb0-e1a9-4bb7-b13d-7947b5aebc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlfilepath = os.path.join(htmldir, prepfilename[0:19]+'.html')\n",
    "texts = get_html_text(htmlfilepath)\n",
    "sentences = sent_tokenize(texts)\n",
    "for s in sentences:\n",
    "    pred = nlpeft(s)\n",
    "    print(format_pred_for_print(pred,s))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
