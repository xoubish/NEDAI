{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70007b0c-45a8-4276-a8fc-1ed23bec83e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-ap_name1\",\n",
    "    2: \"I-ap_name1\",\n",
    "    3: \"B-vz1\",\n",
    "    4: \"I-vz1\",\n",
    "    5: \"B-coordx1\",\n",
    "    6: \"I-coordx1\",\n",
    "    7: \"B-coordy1\",\n",
    "    8: \"I-coordy1\",\n",
    "    9: \"B-type1\",\n",
    "    10: \"I-type1\",\n",
    "}\n",
    "label2id = {\"O\": 0,\n",
    "          \"B-ap_name1\": 1,\n",
    "          \"I-ap_name1\": 2,\n",
    "          \"B-vz1\": 3,\n",
    "          \"I-vz1\": 4,\n",
    "          \"B-coordx1\": 5,\n",
    "          \"I-coordx1\": 6,\n",
    "          \"B-coordy1\": 7,\n",
    "          \"I-coordy1\": 8,\n",
    "          \"B-type1\": 9,\n",
    "          \"I-type1\": 10,\n",
    "         }\n",
    "\n",
    "def get_html_text(f,plength=100):\n",
    "    with open(f) as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "    #to inspect html and identify the class label\n",
    "    #print(soup.prettify()) \n",
    "    sections = soup.find_all('div', class_=\"article-text\")\n",
    "\n",
    "    # Extracting all paragraphs in the section\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ''\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        p = para.get_text()\n",
    "        if (len(p)>plength) and (p[0].isalpha()):\n",
    "            text+=p\n",
    "            #print(f\"Paragraph {i+1}:\", p)\n",
    "            #print('--------------')\n",
    "    #text = re.sub(r'[^a-zA-Z0-9 .,]', '', text)#.lower()\n",
    "    return text\n",
    "    \n",
    "\n",
    "def format_pred_for_print(pred, paragraph, conf = 0.99):\n",
    "    '''\n",
    "    returns a pretty string with the predictions in paragraph highlighted.\n",
    "    pred: prediction output from a pipeline\n",
    "    paragraph: the original text the predictions were made on\n",
    "    '''\n",
    "    \n",
    "    RED_START = '\\x1b[31m'\n",
    "    RED_END = '\\x1b[0m'\n",
    "    \n",
    "    formatted_string=''\n",
    "    end=0\n",
    "    \n",
    "    for entry in pred:\n",
    "        if entry['score']>conf:\n",
    "            start = entry['start']\n",
    "            # add what's in between\n",
    "            formatted_string += paragraph[end:start]\n",
    "            # add the entry\n",
    "            end = entry['end']\n",
    "            label = entry['entity']\n",
    "            score = ' {:.2f}'.format(entry['score'])\n",
    "            formatted_string+= RED_START+'['+paragraph[start:end]+' ('+label+score+')]'+RED_END\n",
    "        \n",
    "    formatted_string+= paragraph[end:]\n",
    "    return(formatted_string)\n",
    "\n",
    "def extract_galaxy_names(sentence, predictions, confidence_level):\n",
    "    galaxy_names = []\n",
    "    current_name = \"\"\n",
    "    current_score = 0.0\n",
    "\n",
    "    for prediction in predictions:\n",
    "        entity = prediction['entity']\n",
    "        word = prediction['word']\n",
    "        score = prediction['score']\n",
    "\n",
    "        if entity == 'B-ap_name1':\n",
    "            # Check if the current name meets the confidence level and add it to the list\n",
    "            if current_name and current_score >= confidence_level:\n",
    "                galaxy_names.append(current_name)\n",
    "\n",
    "            # Start a new galaxy name and reset current score\n",
    "            current_name = word\n",
    "            current_score = score\n",
    "\n",
    "        elif entity == 'I-ap_name1' and current_name:\n",
    "            # Continue building the current galaxy name\n",
    "            current_name += word\n",
    "\n",
    "    # Add the last found name if it meets the confidence level\n",
    "    if current_name and current_score >= confidence_level:\n",
    "        galaxy_names.append(current_name)\n",
    "\n",
    "    return galaxy_names\n",
    "\n",
    "def names_in_paper(htmlfilepath):\n",
    "    texts = get_html_text(htmlfilepath)\n",
    "    sentences = sent_tokenize(texts)\n",
    "    galaxy_names = []\n",
    "    for s in sentences:\n",
    "        pred = nlpeft(s)\n",
    "        ex = extract_galaxy_names(s, pred,confidence_level=0.99)\n",
    "        for e in ex:\n",
    "            galname = re.sub(r'[^a-zA-Z0-9]', '', e)\n",
    "            if len(galname)>1:\n",
    "                galaxy_names.append(galname)\n",
    "    return list(set(galaxy_names))\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "peft_model_id = 'NER-BERT-lora-token-classification/nerpeft0/'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "tokenizerpeft = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "inference_model = AutoModelForTokenClassification.from_pretrained(config.base_model_name_or_path, num_labels=11, id2label=id2label, label2id=label2id,ignore_mismatched_sizes=True)\n",
    "modelpeft = PeftModel.from_pretrained(inference_model, peft_model_id)\n",
    "nlpeft = pipeline(\"ner\", model=modelpeft, tokenizer=tokenizerpeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b1770-7a2d-4a4e-810d-8372747b7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'data/lable_locations2/'\n",
    "\n",
    "count = 0\n",
    "with open('listofnames.txt', 'w') as file:\n",
    "\n",
    "    for prepfilename in tqdm(os.listdir(outdir)):\n",
    "        if count>200:\n",
    "            break\n",
    "        prepfilepath = os.path.join(outdir, prepfilename)\n",
    "        if os.path.isfile(prepfilepath):\n",
    "            # Read in html sections and tables\n",
    "            start_time = time.time()  # Time at the start of the iteration\n",
    "\n",
    "            s = prepfilename.split('.')\n",
    "            htmldir = 'data/'+s[0][0:4]+'-'+s[0][4:]+'-Vol'+s[3][0:3]+'/HTML/'            \n",
    "            htmlfilepath = os.path.join(htmldir, prepfilename[0:19]+'.html')\n",
    "            unique_galnames = names_in_paper(htmlfilepath)\n",
    "    \n",
    "            end_time = time.time()  # Time at the end of the iteration\n",
    "            print(end_time-start_time,'seconds',unique_galnames)\n",
    "            for wor in unique_galnames:\n",
    "                file.write(wor + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b812c-5f58-4b95-946d-cc8ea0e3d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_in_paper('data/2022-ApJ-Vol936/HTML/2022ApJ...936...10M.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b1cb0-e1a9-4bb7-b13d-7947b5aebc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepfilename = '2022ApJ...936...10M_A10M.flt'\n",
    "s = prepfilename.split('.')\n",
    "htmldir = 'data/'+s[0][0:4]+'-'+s[0][4:]+'-Vol'+s[3][0:3]+'/HTML/'\n",
    "htmlfilepath = os.path.join(htmldir, prepfilename[0:19]+'.html')\n",
    "texts = get_html_text(htmlfilepath)\n",
    "sentences = sent_tokenize(texts)\n",
    "for s in sentences[30:350]:\n",
    "    pred = nlpeft(s)\n",
    "    print(format_pred_for_print(pred,s,conf=0.99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9bac2-76c1-44a7-a210-0b019f64067b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a563be-341a-45de-8bda-1bf28e91e061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
